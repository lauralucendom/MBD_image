{
 "cells": [
  {
   "source": [
    "## Importacion de los paquetes utilizados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from results import Results\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(os.listdir(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir=os.path.join(cwd, 'archive/data/train')\n",
    "validation_data_dir=os.path.join(cwd,'archive/data/val')\n",
    "\n",
    "resnet50weight=os.path.join(cwd,'archive/keras_pretrained_models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "vgg16weight=os.path.join(cwd,'archive/keras_pretrained_models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "totalFilesTrain = 0\n",
    "totalFilesVal = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. An√°lisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(train_data_dir):\n",
    "    for name in files:\n",
    "        (base, ext) = os.path.splitext(name) # split base and extension\n",
    "        if ext in ('.jpg', '.png'):          # check the extension\n",
    "            totalFilesTrain += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFilesTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(validation_data_dir):\n",
    "    for name in files:\n",
    "        (base, ext) = os.path.splitext(name) # split base and extension\n",
    "        if ext in ('.jpg', '.png'):          # check the extension\n",
    "            totalFilesVal += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFilesVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train_datagen corresponds to an augmentation tool which will enable us to generate \n",
    "# images for our training dataset according to the configuration set.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, # rescale enables us to normalize the images\n",
    "                rotation_range=10,  # rotation_range randomly rotate images in the range between 0 and 10 degrees\n",
    "                zoom_range = 0.1, # zoom_range zooms the images in the range from 0 to 0.1\n",
    "                width_shift_range=0.1,  # width_shift_range randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # height_shift_range randomly shift images vertically (fraction of total height)\n",
    "                vertical_flip=False, # vertical_flip allows us to unenable the flip of the image in the vertical axis\n",
    "                horizontal_flip=True) # horizontal_flip allows us to enable the flip of the image in the horizontal axis\n",
    "# The test_datagen corresponds to another augmentation tool which will enable us to generate \n",
    "# images for our validation dataset according to the configuration set.\n",
    "# However, for this case only normalization of the images will be used\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train_datagen corresponds to an augmentation tool which will enable us to generate \n",
    "# images for our training dataset according to the configuration set.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, # rescale enables us to normalize the images\n",
    "                rotation_range=10,  # rotation_range randomly rotate images in the range between 0 and 10 degrees\n",
    "                zoom_range = 0.1, # zoom_range zooms the images in the range from 0 to 0.1\n",
    "                width_shift_range=0.1,  # width_shift_range randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,  # height_shift_range randomly shift images vertically (fraction of total height)\n",
    "                vertical_flip=False, # vertical_flip allows us to unenable the flip of the image in the vertical axis\n",
    "                horizontal_flip=True) # horizontal_flip allows us to enable the flip of the image in the horizontal axis\n",
    "# The test_datagen corresponds to another augmentation tool which will enable us to generate \n",
    "# images for our validation dataset according to the configuration set.\n",
    "# However, for this case only normalization of the images will be used\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "if os.path.isdir(cwd + '/archive/random_images') == False:\n",
    "    os.makedirs(cwd + '/archive/random_images')\n",
    "save_dir=os.path.join(cwd,'archive/random_images')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_data_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(200, 200),\n",
    "        # The size of the batches will be 30: the number of samples that will be propagated through the network\n",
    "        batch_size=30,\n",
    "        # The class mode will be binary: 1D numpy array of binary labels\n",
    "        shuffle=True,class_mode='categorical',save_to_dir=save_dir,save_format=\"jpg\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        validation_data_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(200,200),\n",
    "        # The size of the batches will be 30: the number of samples that will be propagated through the network\n",
    "        batch_size=30,\n",
    "        # The class mode will be binary: 1D numpy array of binary labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing of Data Augmentation Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=next(train_generator) # returns the next batch of images and labels\n",
    "print(batch[0].shape)# batch[0] is the images shape\n",
    "print(batch[1].shape)\n",
    "for i in range(7):\n",
    "    # define subplot\n",
    "    image = batch[0][i]\n",
    "    plt.imshow(image)\n",
    "    # plot raw pixel data\n",
    "    #plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pretrained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50tl(input_shape, outclass, sigma='sigmoid'):\n",
    "    \n",
    "    base_model = None\n",
    "    base_model = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights(resnet50weight)\n",
    "    \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16CNNtl(input_shape, outclass, sigma='sigmoid'):\n",
    "    base_model = None\n",
    "    base_model = keras.applications.VGG16(weights=None, include_top=False, input_shape=input_shape)\n",
    "    base_model.load_weights(vgg16weight)\n",
    "        \n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    for i in range(2):\n",
    "        top_model.add(Dense(4096, activation='relu'))\n",
    "        top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(outclass, activation=sigma))\n",
    "\n",
    "    model = None\n",
    "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Preparation of images to enter the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 200,200\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape\n",
    "numclasses=batch[1].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 VGG16 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16CNNtl(input_shape, numclasses, 'softmax')\n",
    "lr = 1e-5 #learning rate \n",
    "decay = 1e-7 #decay\n",
    "optimizer = RMSprop(lr=lr, decay=decay)\n",
    "model.compile(loss='categorical_crossentropy',  \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy']) \n",
    "#As we are dealing with multiple classes the loss will be given by the categorical_crossentropy loss function and the activation function will be softmax since it will assing a probability to each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters that will be uset to train our model VGG16\n",
    "nb_train_samples=totalFilesTrain\n",
    "nb_validation_samples=totalFilesVal\n",
    "batch_size=30\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model fit \n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights will be saved in a .h5 file\n",
    "saveweight1 =  'celebritys_weights_1.h5'\n",
    "model1=\"model1.h5\"\n",
    "model.save_weights(saveweight1)\n",
    "model.save(model1)\n",
    "###top_model.add(Dense(4096, activation='relu'))\n",
    "###top_model.add(Dropout(0.5))\n",
    "###batch_size=30\n",
    "###epochs=50\n",
    "###lr = 1e-5\n",
    "###decay = 1e-7 #0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ploting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "training_acc = history.history['accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "# Visualize loss history\n",
    "fig.add_subplot(121)\n",
    "sns.lineplot(epoch_count, training_loss)\n",
    "sns.lineplot(epoch_count, training_acc)\n",
    "plt.legend(['Training Loss', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss/Acc')\n",
    "plt.title('Training Loss/Accuracy vs Epoch',weight='bold')\n",
    "\n",
    "# Get training and test loss histories\n",
    "val_acc = history.history['val_accuracy']\n",
    "training_acc = history.history['accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "fig.add_subplot(122)\n",
    "sns.lineplot(epoch_count, val_acc)\n",
    "sns.lineplot(epoch_count, training_acc)\n",
    "plt.legend(['Validation Accuracy', 'Training Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epoch',weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Examine functioning of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ben_afflek','elton_john','jerry_seinfeld','madonna','mindy_kaling']\n",
    "test_images=[]\n",
    "for root, dirs, files in os.walk(validation_data_dir):\n",
    "    for name in files:\n",
    "        test_images.append(root+'/'+name)\n",
    "test_imgs=np.random.choice(test_images,6)\n",
    "test_imgs\n",
    "for test in test_imgs:\n",
    "    fig, ax = plt.subplots()\n",
    "    print(test_img)\n",
    "    test_img = os.path.join(validation_data_dir, test)\n",
    "    img = image.load_img(test_img, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.\n",
    "    classes = model.predict(x)\n",
    "    result = np.squeeze(classes)\n",
    "    result_indices = np.argmax(result)\n",
    "    \n",
    "    img = cv2.imread(test_img, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax.axis('off')\n",
    "    plt.title(\"{}, {:.2f}%\".format(labels[result_indices], result[result_indices]*100),size=16,weight='bold')\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('file.json', 'w') as f:\n",
    "#     json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_data_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(200, 200),\n",
    "        # The size of the batches will be 30: the number of samples that will be propagated through the network\n",
    "        batch_size=30,\n",
    "        # The class mode will be binary: 1D numpy array of binary labels\n",
    "        shuffle=True,class_mode='categorical',save_to_dir=save_dir,save_format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict categories\n",
    "predictions = model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1).ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format results and compute classification statistics\n",
    "results = Results(train_generator.class_indices, dataset_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, confusion_matrix, classification = results.compute(test_generator.filenames, test_generator.classes, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print(accuracy, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3613jvsc74a57bd0689c9b04942972b7b0bc087cb3313e93df804602fe33c31f63b51997c5529ec4",
   "display_name": "Python 3.6.13 64-bit ('env_image': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "689c9b04942972b7b0bc087cb3313e93df804602fe33c31f63b51997c5529ec4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}